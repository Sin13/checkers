{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from random import randrange, choice, random\n",
    "from collections import deque, namedtuple\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import utils\n",
    "\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense, Input\n",
    "from tensorflow.keras.losses import MSE\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "from kaggle_environments import evaluate, make"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the random seed for TensorFlow\n",
    "tf.random.set_seed(0)\n",
    "MEMORY_SIZE = 100_000     # size of memory buffer\n",
    "GAMMA = 0.995             # discount factor\n",
    "ALPHA = 1e-3              # learning rate  \n",
    "NUM_STEPS_FOR_UPDATE = 4  # perform a learning update every C time steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ConnectX - Kaggle Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = make(\"connectx\", debug=True)\n",
    "env.render()\n",
    "print(env.name, env.version)\n",
    "print(\"Default Agents: \", *env.agents)\n",
    "print('env: ', env.specification.observation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_size = (env.specification.configuration.rows.default, env.specification.configuration.columns.default)\n",
    "num_actions = env.specification.configuration.columns.default\n",
    "\n",
    "state_size = (env.configuration.rows * env.configuration.columns,)\n",
    "num_actions = env.configuration.columns\n",
    "\n",
    "print('State Shape:', state_size)\n",
    "print('Number of actions:', num_actions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deep Q-Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the Q-Network\n",
    "q_network = Sequential([\n",
    "    Input(shape=state_size),                      \n",
    "    Dense(units=25, activation='relu'),            \n",
    "    Dense(units=15, activation='relu'),            \n",
    "    Dense(units=num_actions, activation='linear'),\n",
    "])\n",
    "\n",
    "# Create the target Q^-Network\n",
    "target_q_network = Sequential([\n",
    "    Input(shape=state_size),                      \n",
    "    Dense(units=25, activation='relu'),            \n",
    "    Dense(units=15, activation='relu'),            \n",
    "    Dense(units=num_actions, activation='linear'),\n",
    "])\n",
    "\n",
    "optimizer = Adam(learning_rate=ALPHA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Experience Replay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store experiences as named tuples\n",
    "experience = namedtuple(\"Experience\", field_names=[\"state\", \"action\", \"reward\", \"next_state\", \"done\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Epsilon-greedy action function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def find_free_columns(flat_board):\n",
    "    board = np.array(flat_board).reshape(6,7)\n",
    "    free_columns = []\n",
    "    for c in range(7):\n",
    "        if 0 in board[:, c]:\n",
    "            free_columns.append(c)\n",
    "    return free_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_action(state, configuration, q_values, epsilon=0):\n",
    "    free_columns = find_free_columns(state)\n",
    "    print('free_columns: ', free_columns)\n",
    "    if random() > epsilon:\n",
    "        # todo: handle the situation when there is no empty space left on the board\n",
    "        q_values_ndarray = q_values.numpy()[0]\n",
    "        \n",
    "        return q_values_ndarray[free_columns[np.argmax(q_values_ndarray[free_columns]).item()]]\n",
    "    else:\n",
    "        return choice(free_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-3.    1.    0.5   1.23 -2.    5.3   0.02]\n",
      "[1, 2, 5]\n",
      "g3:  [1.  0.5 5.3]\n",
      "g3max:  2\n",
      "5\n",
      "5.3\n"
     ]
    }
   ],
   "source": [
    "gg2 = np.arange(7)\n",
    "gg2 = np.array([-3, 1, 0.5, 1.23, -2, 5.3, 0.02])\n",
    "g1 = np.array([1, 0, 0, 2, 1, 0, 2, 1, 0, 0, 2, 1, 0, 2, 1, 0, 0, 2, 1, 0, 2, 1, 0, 0, 2, 1, 0, 2, 1, 0, 0, 2, 1, 0, 2, 1, 0, 0, 2, 1, 0, 2])\n",
    "foo = g1.reshape(6, 7)\n",
    "print(gg2)\n",
    "bar = find_free_columns(g1)\n",
    "print(bar)\n",
    "ggg3 = gg2[bar]\n",
    "print('g3: ', ggg3)\n",
    "g3max = np.argmax(ggg3)\n",
    "print('g3max: ', g3max)\n",
    "print(bar[g3max])\n",
    "print(gg2[bar[g3max]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1 2]\n",
      " [3 4 5]]\n",
      "[[2]\n",
      " [2]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(2, 1)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.arange(6).reshape((2, 3))\n",
    "print(x)\n",
    "res = np.argmax(x, axis=1, keepdims=True)\n",
    "print(res)\n",
    "\n",
    "res.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_agent(observation, configuration):\n",
    "    if random.random() > epsilon:\n",
    "        return np.argmax(q_values.numpy()[0]).item()\n",
    "    else:\n",
    "        return randrange(num_actions)\n",
    "    return choice([c for c in range(configuration.columns) if observation.board[c] == 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_loss(experiences, gamma, q_network, target_q_network):\n",
    "    # Unpack the mini-batch of experience tuples\n",
    "    states, actions, rewards, next_states, done_vals = experiences\n",
    "    \n",
    "    # Compute max Q^(s,a)\n",
    "    max_qsa = tf.reduce_max(target_q_network(next_states), axis=-1)\n",
    "    \n",
    "    # Set y = R if episode terminates, otherwise set y = R + Î³ max Q^(s,a).\n",
    "    y_targets = rewards+((1-done_vals)*gamma*max_qsa)\n",
    "    \n",
    "    # Get the q_values\n",
    "    q_values = q_network(states)\n",
    "    q_values = tf.gather_nd(q_values, tf.stack([tf.range(q_values.shape[0]),\n",
    "                                                tf.cast(actions, tf.int32)], axis=1))   \n",
    "    # Compute the loss\n",
    "    loss = MSE(y_targets, q_values) \n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Learn function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def agent_learn(experiences, gamma):\n",
    "    \n",
    "    # Calculate the loss\n",
    "    with tf.GradientTape() as tape:\n",
    "        loss = compute_loss(experiences, gamma, q_network, target_q_network)\n",
    "\n",
    "    # Get the gradients of the loss with respect to the weights.\n",
    "    gradients = tape.gradient(loss, q_network.trainable_variables)\n",
    "    \n",
    "    # Update the weights of the q_network.\n",
    "    optimizer.apply_gradients(zip(gradients, q_network.trainable_variables))\n",
    "\n",
    "    # update the weights of target q_network\n",
    "    utils.update_target_network(q_network, target_q_network)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deep-Q Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "free_columns:  [0, 1, 2, 3, 4, 5, 6]\n",
      "action  4\n",
      "next_state  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 1, 0, 0]\n",
      "rr  0\n",
      "done  False\n",
      "free_columns:  [0, 1, 2, 3, 4, 5, 6]\n",
      "action  5\n",
      "next_state  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 1, 1, 2]\n",
      "rr  0\n",
      "done  False\n",
      "free_columns:  [0, 1, 2, 3, 4, 5, 6]\n",
      "action  0\n",
      "next_state  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 2, 0, 0, 1, 0, 0, 0, 1, 1, 2]\n",
      "rr  0\n",
      "done  False\n",
      "free_columns:  [0, 1, 2, 3, 4, 5, 6]\n",
      "action  0\n",
      "next_state  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 1, 0, 0, 0, 2, 0, 2, 1, 0, 0, 0, 1, 1, 2]\n",
      "rr  0\n",
      "done  False\n",
      "free_columns:  [0, 1, 2, 3, 4, 5, 6]\n",
      "action  5\n",
      "next_state  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 1, 0, 0, 0, 2, 1, 2, 1, 0, 2, 0, 1, 1, 2]\n",
      "rr  0\n",
      "done  False\n",
      "free_columns:  [0, 1, 2, 3, 4, 5, 6]\n",
      "action  4\n",
      "next_state  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 2, 0, 2, 1, 0, 0, 0, 2, 1, 2, 1, 0, 2, 0, 1, 1, 2]\n",
      "rr  0\n",
      "done  False\n",
      "free_columns:  [0, 1, 2, 3, 4, 5, 6]\n",
      "action  1\n",
      "next_state  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 2, 0, 0, 0, 0, 2, 0, 2, 1, 0, 0, 0, 2, 1, 2, 1, 1, 2, 0, 1, 1, 2]\n",
      "rr  -1\n",
      "done  True\n",
      "Episode 1 | Total point average of the last 100 episodes: -1.00free_columns:  [0, 1, 2, 3, 4, 5, 6]\n",
      "action  4\n",
      "next_state  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 1, 0, 0]\n",
      "rr  0\n",
      "done  False\n",
      "free_columns:  [0, 1, 2, 3, 4, 5, 6]\n",
      "action  1\n",
      "next_state  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 1, 2, 0, 1, 0, 0]\n",
      "rr  0\n",
      "done  False\n",
      "free_columns:  [0, 1, 2, 3, 4, 5, 6]\n",
      "action  1\n",
      "next_state  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 1, 0, 0, 2, 0, 0, 0, 1, 2, 0, 1, 0, 0]\n",
      "rr  0\n",
      "done  False\n",
      "free_columns:  [0, 1, 2, 3, 4, 5, 6]\n",
      "action  1\n",
      "next_state  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 1, 0, 0, 2, 0, 0, 0, 1, 0, 0, 2, 0, 0, 0, 1, 2, 0, 1, 0, 0]\n",
      "rr  0\n",
      "done  False\n",
      "free_columns:  [0, 1, 2, 3, 4, 5, 6]\n",
      "action  2\n",
      "next_state  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 1, 0, 0, 2, 0, 0, 0, 1, 1, 0, 2, 0, 0, 0, 1, 2, 2, 1, 0, 0]\n",
      "rr  0\n",
      "done  False\n",
      "free_columns:  [0, 1, 2, 3, 4, 5, 6]\n",
      "action  1\n",
      "next_state  [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 1, 0, 0, 2, 0, 0, 0, 1, 1, 0, 2, 0, 0, 0, 1, 2, 2, 1, 2, 0]\n",
      "rr  0\n",
      "done  False\n",
      "free_columns:  [0, 1, 2, 3, 4, 5, 6]\n",
      "action  1\n",
      "next_state  [0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 1, 0, 0, 2, 0, 0, 0, 1, 1, 0, 2, 0, 0, 2, 1, 2, 2, 1, 2, 0]\n",
      "rr  0\n",
      "done  False\n",
      "free_columns:  [0, 2, 3, 4, 5, 6]\n",
      "action  6\n",
      "next_state  [0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 2, 0, 0, 2, 0, 0, 0, 1, 0, 0, 2, 0, 0, 0, 1, 1, 0, 2, 0, 0, 2, 1, 2, 2, 1, 2, 1]\n",
      "rr  0\n",
      "done  False\n",
      "free_columns:  [0, 2, 3, 4, 5, 6]\n",
      "action  2\n",
      "next_state  [0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 2, 2, 0, 2, 0, 0, 0, 1, 1, 0, 2, 0, 0, 0, 1, 1, 0, 2, 0, 0, 2, 1, 2, 2, 1, 2, 1]\n",
      "rr  0\n",
      "done  False\n",
      "free_columns:  [0, 2, 3, 4, 5, 6]\n",
      "action  0\n",
      "next_state  [0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 2, 2, 0, 2, 0, 0, 0, 1, 1, 0, 2, 0, 0, 1, 1, 1, 2, 2, 0, 0, 2, 1, 2, 2, 1, 2, 1]\n",
      "rr  0\n",
      "done  False\n",
      "free_columns:  [0, 2, 3, 4, 5, 6]\n",
      "action  4\n",
      "next_state  [0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 2, 2, 0, 2, 0, 0, 0, 1, 1, 0, 2, 0, 0, 1, 1, 1, 2, 2, 0, 2, 2, 1, 2, 2, 1, 2, 1]\n",
      "rr  0\n",
      "done  False\n",
      "free_columns:  [0, 2, 3, 4, 5, 6]\n",
      "action  6\n",
      "next_state  [0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 2, 2, 0, 2, 0, 0, 0, 1, 1, 2, 2, 0, 1, 1, 1, 1, 2, 2, 0, 2, 2, 1, 2, 2, 1, 2, 1]\n",
      "rr  -1\n",
      "done  True\n",
      "Episode 2 | Total point average of the last 100 episodes: -1.00free_columns:  [0, 1, 2, 3, 4, 5, 6]\n",
      "action  5\n",
      "next_state  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 1, 0]\n",
      "rr  0\n",
      "done  False\n",
      "free_columns:  [0, 1, 2, 3, 4, 5, 6]\n",
      "action  5\n",
      "next_state  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 1, 2]\n",
      "rr  0\n",
      "done  False\n",
      "free_columns:  [0, 1, 2, 3, 4, 5, 6]\n",
      "action  4\n",
      "next_state  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 1, 1, 2]\n",
      "rr  0\n",
      "done  False\n",
      "free_columns:  [0, 1, 2, 3, 4, 5, 6]\n",
      "action  1\n",
      "next_state  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 2, 2, 0, 1, 0, 0, 1, 1, 2]\n",
      "rr  0\n",
      "done  False\n",
      "free_columns:  [0, 1, 2, 3, 4, 5, 6]\n",
      "action  4\n",
      "next_state  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 2, 2, 0, 1, 0, 0, 1, 1, 2]\n",
      "rr  0\n",
      "done  False\n",
      "free_columns:  [0, 1, 2, 3, 4, 5, 6]\n",
      "action  1\n",
      "next_state  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 2, 0, 0, 2, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 2, 2, 0, 1, 0, 0, 1, 1, 2]\n",
      "rr  0\n",
      "done  False\n",
      "free_columns:  [0, 1, 2, 3, 4, 5, 6]\n",
      "action  0\n",
      "next_state  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 2, 0, 0, 2, 0, 0, 2, 1, 0, 0, 1, 0, 0, 1, 2, 2, 1, 1, 0, 0, 1, 1, 2]\n",
      "rr  0\n",
      "done  False\n",
      "free_columns:  [0, 1, 2, 3, 4, 5, 6]\n",
      "action  1\n",
      "next_state  [0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 2, 0, 0, 1, 0, 0, 0, 2, 0, 0, 2, 0, 0, 2, 1, 0, 0, 1, 0, 0, 1, 2, 2, 1, 1, 0, 0, 1, 1, 2]\n",
      "rr  0\n",
      "done  False\n",
      "free_columns:  [0, 1, 2, 3, 4, 6]\n",
      "action  2\n",
      "next_state  [0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 2, 0, 0, 1, 0, 0, 0, 2, 0, 0, 2, 0, 0, 2, 1, 2, 0, 1, 0, 0, 1, 2, 2, 1, 1, 1, 0, 1, 1, 2]\n",
      "rr  0\n",
      "done  False\n",
      "free_columns:  [0, 1, 2, 3, 4, 6]\n",
      "action  1\n",
      "next_state  [0, 0, 0, 0, 0, 2, 0, 0, 1, 0, 0, 0, 2, 0, 0, 1, 0, 0, 0, 2, 2, 0, 2, 0, 0, 2, 1, 2, 0, 1, 0, 0, 1, 2, 2, 1, 1, 1, 0, 1, 1, 2]\n",
      "rr  -1\n",
      "done  True\n",
      "Episode 3 | Total point average of the last 100 episodes: -1.00free_columns:  [0, 1, 2, 3, 4, 5, 6]\n",
      "action  2\n",
      "next_state  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 2, 0]\n",
      "rr  0\n",
      "done  False\n",
      "free_columns:  [0, 1, 2, 3, 4, 5, 6]\n",
      "action  0\n",
      "next_state  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 1, 0, 1, 0, 0, 2, 0]\n",
      "rr  0\n",
      "done  False\n",
      "free_columns:  [0, 1, 2, 3, 4, 5, 6]\n",
      "action  2\n",
      "next_state  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 1, 0, 1, 0, 2, 2, 0]\n",
      "rr  0\n",
      "done  False\n",
      "free_columns:  [0, 1, 2, 3, 4, 5, 6]\n",
      "action  2\n",
      "next_state  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 1, 2, 1, 0, 2, 2, 0]\n",
      "rr  0\n",
      "done  False\n",
      "free_columns:  [0, 1, 2, 3, 4, 5, 6]\n",
      "action  3\n",
      "next_state  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 2, 0, 2, 0, 0, 0, 0, 1, 2, 1, 1, 2, 2, 0]\n",
      "rr  0\n",
      "done  False\n",
      "free_columns:  [0, 1, 2, 3, 4, 5, 6]\n",
      "action  0\n",
      "next_state  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 2, 0, 2, 0, 2, 0, 0, 1, 2, 1, 1, 2, 2, 0]\n",
      "rr  0\n",
      "done  False\n",
      "free_columns:  [0, 1, 2, 3, 4, 5, 6]\n",
      "action  0\n",
      "next_state  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 2, 0, 0, 2, 0, 2, 0, 2, 0, 0, 1, 2, 1, 1, 2, 2, 0]\n",
      "rr  0\n",
      "done  False\n",
      "free_columns:  [0, 1, 2, 3, 4, 5, 6]\n",
      "action  5\n",
      "next_state  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 2, 0, 0, 2, 0, 2, 0, 2, 1, 0, 1, 2, 1, 1, 2, 2, 2]\n",
      "rr  0\n",
      "done  False\n",
      "free_columns:  [0, 1, 2, 3, 4, 5, 6]\n",
      "action  3\n",
      "next_state  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 2, 0, 0, 2, 2, 2, 1, 2, 1, 0, 1, 2, 1, 1, 2, 2, 2]\n",
      "rr  0\n",
      "done  False\n",
      "free_columns:  [0, 1, 2, 3, 4, 5, 6]\n",
      "action  5\n",
      "next_state  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 2, 0, 0, 1, 0, 1, 0, 2, 1, 0, 2, 2, 2, 1, 2, 1, 0, 1, 2, 1, 1, 2, 2, 2]\n",
      "rr  -1\n",
      "done  True\n",
      "Episode 4 | Total point average of the last 100 episodes: -1.00free_columns:  [0, 1, 2, 3, 4, 5, 6]\n",
      "action  6\n",
      "next_state  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 1]\n",
      "rr  0\n",
      "done  False\n",
      "free_columns:  [0, 1, 2, 3, 4, 5, 6]\n",
      "action  2\n",
      "next_state  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 1, 2, 0, 0, 1]\n",
      "rr  0\n",
      "done  False\n",
      "free_columns:  [0, 1, 2, 3, 4, 5, 6]\n",
      "action  3\n",
      "next_state  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 2, 1, 2, 2, 0, 1]\n",
      "rr  0\n",
      "done  False\n",
      "free_columns:  [0, 1, 2, 3, 4, 5, 6]\n",
      "action  6\n",
      "next_state  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 1, 0, 0, 1, 0, 2, 1, 2, 2, 0, 1]\n",
      "rr  0\n",
      "done  False\n",
      "free_columns:  [0, 1, 2, 3, 4, 5, 6]\n",
      "action  5\n",
      "next_state  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 2, 0, 0, 0, 1, 0, 0, 1, 0, 2, 1, 2, 2, 1, 1]\n",
      "rr  0\n",
      "done  False\n",
      "free_columns:  [0, 1, 2, 3, 4, 5, 6]\n",
      "action  6\n",
      "next_state  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 2, 0, 0, 2, 0, 0, 0, 1, 0, 2, 1, 0, 2, 1, 2, 2, 1, 1]\n",
      "rr  0\n",
      "done  False\n",
      "free_columns:  [0, 1, 2, 3, 4, 5, 6]\n",
      "action  4\n",
      "next_state  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 2, 0, 0, 2, 0, 2, 0, 1, 1, 2, 1, 0, 2, 1, 2, 2, 1, 1]\n",
      "rr  0\n",
      "done  False\n",
      "free_columns:  [0, 1, 2, 3, 4, 5, 6]\n",
      "action  2\n",
      "next_state  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 2, 2, 0, 2, 0, 2, 1, 1, 1, 2, 1, 0, 2, 1, 2, 2, 1, 1]\n",
      "rr  0\n",
      "done  False\n",
      "free_columns:  [0, 1, 2, 3, 4, 5, 6]\n",
      "action  6\n",
      "next_state  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 2, 0, 1, 0, 0, 0, 2, 2, 0, 2, 0, 2, 1, 1, 1, 2, 1, 0, 2, 1, 2, 2, 1, 1]\n",
      "rr  0\n",
      "done  False\n",
      "free_columns:  [0, 1, 2, 3, 4, 5, 6]\n",
      "action  0\n",
      "next_state  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 2, 0, 1, 0, 2, 0, 2, 2, 0, 2, 0, 2, 1, 1, 1, 2, 1, 1, 2, 1, 2, 2, 1, 1]\n",
      "rr  0\n",
      "done  False\n",
      "free_columns:  [0, 1, 2, 3, 4, 5, 6]\n",
      "action  3\n",
      "next_state  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 2, 0, 1, 0, 2, 0, 2, 2, 0, 2, 2, 2, 1, 1, 1, 2, 1, 1, 2, 1, 2, 2, 1, 1]\n",
      "rr  0\n",
      "done  False\n",
      "free_columns:  [0, 1, 2, 3, 4, 5, 6]\n",
      "action  3\n",
      "next_state  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 2, 0, 1, 2, 2, 0, 2, 2, 0, 2, 2, 2, 1, 1, 1, 2, 1, 1, 2, 1, 2, 2, 1, 1]\n",
      "rr  0\n",
      "done  False\n",
      "free_columns:  [0, 1, 2, 3, 4, 5, 6]\n",
      "action  3\n",
      "next_state  [0, 0, 0, 1, 0, 0, 2, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 2, 0, 1, 2, 2, 0, 2, 2, 0, 2, 2, 2, 1, 1, 1, 2, 1, 1, 2, 1, 2, 2, 1, 1]\n",
      "rr  0\n",
      "done  False\n",
      "free_columns:  [0, 1, 2, 4, 5]\n",
      "action  0\n",
      "next_state  [0, 0, 0, 1, 0, 0, 2, 0, 0, 0, 1, 0, 0, 1, 1, 2, 0, 1, 2, 0, 1, 2, 2, 0, 2, 2, 0, 2, 2, 2, 1, 1, 1, 2, 1, 1, 2, 1, 2, 2, 1, 1]\n",
      "rr  -1\n",
      "done  True\n",
      "Episode 5 | Total point average of the last 100 episodes: -1.00free_columns:  [0, 1, 2, 3, 4, 5, 6]\n",
      "action  0\n",
      "next_state  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 2, 0, 0]\n",
      "rr  0\n",
      "done  False\n",
      "free_columns:  [0, 1, 2, 3, 4, 5, 6]\n",
      "action  0\n",
      "next_state  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 2, 0, 2]\n",
      "rr  0\n",
      "done  False\n",
      "free_columns:  [0, 1, 2, 3, 4, 5, 6]\n",
      "action  4\n",
      "next_state  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 2, 0, 0, 2, 0, 2]\n",
      "rr  0\n",
      "done  False\n",
      "free_columns:  [0, 1, 2, 3, 4, 5, 6]\n",
      "action  0\n",
      "next_state  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 2, 0, 0, 1, 0, 0, 1, 2, 0, 0, 2, 0, 2]\n",
      "rr  0\n",
      "done  False\n",
      "free_columns:  [0, 1, 2, 3, 4, 5, 6]\n",
      "action  0\n",
      "next_state  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 2, 0, 0, 1, 0, 0, 1, 2, 0, 0, 2, 0, 2]\n",
      "rr  1\n",
      "done  True\n",
      "Episode 6 | Total point average of the last 100 episodes: -0.67free_columns:  [0, 1, 2, 3, 4, 5, 6]\n",
      "action  4\n",
      "next_state  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 1, 0, 0]\n",
      "rr  0\n",
      "done  False\n",
      "free_columns:  [0, 1, 2, 3, 4, 5, 6]\n",
      "action  4\n",
      "next_state  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 2, 0, 0, 1, 2, 0]\n",
      "rr  0\n",
      "done  False\n",
      "free_columns:  [0, 1, 2, 3, 4, 5, 6]\n",
      "action  4\n",
      "next_state  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 2, 0, 2, 1, 2, 0]\n",
      "rr  0\n",
      "done  False\n",
      "free_columns:  [0, 1, 2, 3, 4, 5, 6]\n",
      "action  2\n",
      "next_state  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 2, 0, 0, 2, 1, 2, 1, 2, 0]\n",
      "rr  0\n",
      "done  False\n",
      "free_columns:  [0, 1, 2, 3, 4, 5, 6]\n",
      "action  5\n",
      "next_state  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 2, 0, 0, 2, 1, 2, 1, 2, 0]\n",
      "rr  0\n",
      "done  False\n",
      "free_columns:  [0, 1, 2, 3, 4, 5, 6]\n",
      "action  0\n",
      "next_state  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 2, 0, 1, 2, 0, 1, 2, 1, 2, 1, 2, 0]\n",
      "rr  0\n",
      "done  False\n",
      "free_columns:  [0, 1, 2, 3, 4, 5, 6]\n",
      "action  6\n",
      "next_state  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 2, 0, 1, 2, 2, 1, 2, 1, 2, 1, 2, 1]\n",
      "rr  0\n",
      "done  False\n",
      "free_columns:  [0, 1, 2, 3, 4, 5, 6]\n",
      "action  5\n",
      "next_state  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 1, 1, 0, 2, 0, 2, 0, 1, 2, 2, 1, 2, 1, 2, 1, 2, 1]\n",
      "rr  0\n",
      "done  False\n",
      "free_columns:  [0, 1, 2, 3, 4, 5, 6]\n",
      "action  4\n",
      "next_state  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 2, 0, 0, 0, 0, 0, 1, 1, 0, 2, 0, 2, 0, 1, 2, 2, 1, 2, 1, 2, 1, 2, 1]\n",
      "rr  1\n",
      "done  True\n",
      "Episode 7 | Total point average of the last 100 episodes: -0.43free_columns:  [0, 1, 2, 3, 4, 5, 6]\n",
      "action  4\n",
      "next_state  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 1, 0, 0]\n",
      "rr  0\n",
      "done  False\n",
      "free_columns:  [0, 1, 2, 3, 4, 5, 6]\n",
      "action  4\n",
      "next_state  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 2, 0, 2, 1, 0, 0]\n",
      "rr  0\n",
      "done  False\n",
      "free_columns:  [0, 1, 2, 3, 4, 5, 6]\n",
      "action  3\n",
      "next_state  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 2, 2, 2, 1, 0, 0]\n",
      "rr  0\n",
      "done  False\n",
      "free_columns:  [0, 1, 2, 3, 4, 5, 6]\n",
      "action  0\n",
      "next_state  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 1, 1, 0, 0, 1, 2, 2, 2, 1, 0, 0]\n",
      "rr  0\n",
      "done  False\n",
      "free_columns:  [0, 1, 2, 3, 4, 5, 6]\n",
      "action  3\n",
      "next_state  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 2, 2, 0, 1, 1, 0, 0, 1, 2, 2, 2, 1, 0, 0]\n",
      "rr  0\n",
      "done  False\n",
      "free_columns:  [0, 1, 2, 3, 4, 5, 6]\n",
      "action  2\n",
      "next_state  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 2, 2, 1, 1, 1, 0, 0, 1, 2, 2, 2, 1, 2, 0]\n",
      "rr  0\n",
      "done  False\n",
      "free_columns:  [0, 1, 2, 3, 4, 5, 6]\n",
      "action  0\n",
      "next_state  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 2, 1, 0, 0, 0, 2, 2, 1, 1, 1, 0, 0, 1, 2, 2, 2, 1, 2, 0]\n",
      "rr  0\n",
      "done  False\n",
      "free_columns:  [0, 1, 2, 3, 4, 5, 6]\n",
      "action  1\n",
      "next_state  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 2, 1, 0, 0, 0, 2, 2, 1, 1, 1, 0, 0, 1, 2, 2, 2, 1, 2, 2]\n",
      "rr  0\n",
      "done  False\n",
      "free_columns:  [0, 1, 2, 3, 4, 5, 6]\n",
      "action  5\n",
      "next_state  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 2, 1, 0, 0, 0, 2, 2, 1, 1, 1, 1, 0, 1, 2, 2, 2, 1, 2, 2]\n",
      "rr  1\n",
      "done  True\n",
      "Episode 8 | Total point average of the last 100 episodes: -0.25free_columns:  [0, 1, 2, 3, 4, 5, 6]\n",
      "action  0\n",
      "next_state  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 2, 0]\n",
      "rr  0\n",
      "done  False\n",
      "free_columns:  [0, 1, 2, 3, 4, 5, 6]\n",
      "action  2\n",
      "next_state  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 1, 0, 1, 0, 0, 2, 0]\n",
      "rr  0\n",
      "done  False\n",
      "free_columns:  [0, 1, 2, 3, 4, 5, 6]\n",
      "action  1\n",
      "next_state  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 1, 1, 1, 0, 0, 2, 0]\n",
      "rr  0\n",
      "done  False\n",
      "free_columns:  [0, 1, 2, 3, 4, 5, 6]\n",
      "action  1\n",
      "next_state  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 1, 2, 0, 0, 2, 0, 1, 1, 1, 0, 0, 2, 0]\n",
      "rr  0\n",
      "done  False\n",
      "free_columns:  [0, 1, 2, 3, 4, 5, 6]\n",
      "action  5\n",
      "next_state  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 0, 0, 1, 0, 0, 1, 2, 0, 0, 2, 0, 1, 1, 1, 0, 0, 2, 0]\n",
      "rr  0\n",
      "done  False\n",
      "free_columns:  [0, 1, 2, 3, 4, 5, 6]\n",
      "action  0\n",
      "next_state  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 0, 0, 1, 0, 1, 1, 2, 0, 0, 2, 0, 1, 1, 1, 0, 2, 2, 0]\n",
      "rr  0\n",
      "done  False\n",
      "free_columns:  [0, 1, 2, 3, 4, 5, 6]\n",
      "action  0\n",
      "next_state  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 1, 2, 2, 0, 0, 1, 0, 1, 1, 2, 0, 0, 2, 0, 1, 1, 1, 0, 2, 2, 0]\n",
      "rr  0\n",
      "done  False\n",
      "free_columns:  [0, 1, 2, 3, 4, 5, 6]\n",
      "action  2\n",
      "next_state  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 1, 0, 0, 2, 0, 1, 2, 2, 0, 0, 1, 0, 1, 1, 2, 0, 0, 2, 0, 1, 1, 1, 0, 2, 2, 0]\n",
      "rr  0\n",
      "done  False\n",
      "free_columns:  [0, 1, 2, 3, 4, 5, 6]\n",
      "action  0\n",
      "next_state  [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 2, 0, 1, 0, 0, 2, 0, 1, 2, 2, 0, 0, 1, 0, 1, 1, 2, 0, 0, 2, 0, 1, 1, 1, 2, 2, 2, 0]\n",
      "rr  -1\n",
      "done  True\n",
      "Episode 9 | Total point average of the last 100 episodes: -0.33free_columns:  [0, 1, 2, 3, 4, 5, 6]\n",
      "action  6\n",
      "next_state  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 1]\n",
      "rr  0\n",
      "done  False\n",
      "free_columns:  [0, 1, 2, 3, 4, 5, 6]\n",
      "action  3\n",
      "next_state  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 1, 0, 2, 1]\n",
      "rr  0\n",
      "done  False\n",
      "free_columns:  [0, 1, 2, 3, 4, 5, 6]\n",
      "action  4\n",
      "next_state  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 2, 0, 1, 1, 2, 1]\n",
      "rr  0\n",
      "done  False\n",
      "free_columns:  [0, 1, 2, 3, 4, 5, 6]\n",
      "action  3\n",
      "next_state  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 2, 0, 1, 0, 0, 0, 0, 2, 0, 1, 1, 2, 1]\n",
      "rr  0\n",
      "done  False\n",
      "free_columns:  [0, 1, 2, 3, 4, 5, 6]\n",
      "action  1\n",
      "next_state  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 2, 0, 0, 0, 0, 2, 0, 1, 0, 0, 0, 0, 2, 2, 1, 1, 2, 1]\n",
      "rr  0\n",
      "done  False\n",
      "free_columns:  [0, 1, 2, 3, 4, 5, 6]\n",
      "action  3\n",
      "next_state  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 2, 0, 0, 0, 0, 2, 0, 1, 0, 0, 0, 0, 2, 2, 1, 1, 2, 1]\n",
      "rr  0\n",
      "done  False\n",
      "free_columns:  [0, 1, 2, 3, 4, 5, 6]\n",
      "action  5\n",
      "next_state  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 2, 0, 1, 0, 0, 0, 0, 1, 0, 2, 0, 0, 0, 0, 2, 0, 1, 0, 1, 0, 0, 2, 2, 1, 1, 2, 1]\n",
      "rr  0\n",
      "done  False\n",
      "free_columns:  [0, 1, 2, 3, 4, 5, 6]\n",
      "action  0\n",
      "next_state  [0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 2, 0, 0, 0, 0, 2, 0, 1, 0, 0, 0, 0, 1, 0, 2, 0, 0, 0, 0, 2, 0, 1, 0, 1, 0, 1, 2, 2, 1, 1, 2, 1]\n",
      "rr  0\n",
      "done  False\n",
      "free_columns:  [0, 1, 2, 3, 4, 5, 6]\n",
      "action  0\n",
      "next_state  [0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 2, 0, 0, 0, 0, 2, 0, 1, 0, 0, 0, 2, 1, 0, 2, 0, 0, 0, 1, 2, 0, 1, 0, 1, 0, 1, 2, 2, 1, 1, 2, 1]\n",
      "rr  0\n",
      "done  False\n",
      "free_columns:  [0, 1, 2, 3, 4, 5, 6]\n",
      "action  1\n",
      "next_state  [0, 1, 0, 0, 0, 0, 0, 0, 2, 0, 2, 0, 0, 0, 0, 2, 0, 1, 0, 0, 0, 2, 1, 0, 2, 0, 2, 0, 1, 2, 0, 1, 0, 1, 0, 1, 2, 2, 1, 1, 2, 1]\n",
      "rr  0\n",
      "done  False\n",
      "free_columns:  [0, 2, 3, 4, 5, 6]\n",
      "action  4\n",
      "next_state  [0, 1, 0, 0, 0, 0, 0, 0, 2, 0, 2, 0, 0, 0, 0, 2, 0, 1, 0, 0, 0, 2, 1, 0, 2, 0, 2, 0, 1, 2, 0, 1, 1, 1, 2, 1, 2, 2, 1, 1, 2, 1]\n",
      "rr  0\n",
      "done  False\n",
      "free_columns:  [0, 2, 3, 4, 5, 6]\n",
      "action  2\n",
      "next_state  [0, 1, 0, 0, 0, 0, 0, 0, 2, 0, 2, 0, 0, 0, 0, 2, 0, 1, 0, 0, 0, 2, 1, 0, 2, 0, 2, 0, 1, 2, 1, 1, 1, 1, 2, 1, 2, 2, 1, 1, 2, 1]\n",
      "rr  1\n",
      "done  True\n",
      "Episode 10 | Total point average of the last 100 episodes: -0.20free_columns:  [0, 1, 2, 3, 4, 5, 6]\n",
      "action  6\n",
      "next_state  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 1]\n",
      "rr  0\n",
      "done  False\n",
      "free_columns:  [0, 1, 2, 3, 4, 5, 6]\n",
      "action  5\n",
      "next_state  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 2, 0, 1, 1]\n",
      "rr  0\n",
      "done  False\n",
      "free_columns:  [0, 1, 2, 3, 4, 5, 6]\n",
      "action  2\n",
      "next_state  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 2, 1, 2, 0, 1, 1]\n",
      "rr  0\n",
      "done  False\n",
      "free_columns:  [0, 1, 2, 3, 4, 5, 6]\n",
      "action  0\n",
      "next_state  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 2, 1, 2, 1, 2, 0, 1, 1]\n",
      "rr  0\n",
      "done  False\n",
      "free_columns:  [0, 1, 2, 3, 4, 5, 6]\n",
      "action  5\n",
      "next_state  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 2, 0, 0, 0, 1, 2, 1, 2, 1, 2, 0, 1, 1]\n",
      "rr  0\n",
      "done  False\n",
      "free_columns:  [0, 1, 2, 3, 4, 5, 6]\n",
      "action  0\n",
      "next_state  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 2, 0, 1, 2, 0, 0, 0, 1, 2, 1, 2, 1, 2, 0, 1, 1]\n",
      "rr  0\n",
      "done  False\n",
      "free_columns:  [0, 1, 2, 3, 4, 5, 6]\n",
      "action  1\n",
      "next_state  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 1, 0, 0, 0, 2, 0, 1, 2, 2, 0, 0, 1, 2, 1, 2, 1, 2, 0, 1, 1]\n",
      "rr  0\n",
      "done  False\n",
      "free_columns:  [0, 1, 2, 3, 4, 5, 6]\n",
      "action  3\n",
      "next_state  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 2, 1, 0, 0, 0, 2, 0, 1, 2, 2, 1, 0, 1, 2, 1, 2, 1, 2, 0, 1, 1]\n",
      "rr  0\n",
      "done  False\n",
      "free_columns:  [0, 1, 2, 3, 4, 5, 6]\n",
      "action  2\n",
      "next_state  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 2, 0, 2, 1, 1, 0, 0, 2, 0, 1, 2, 2, 1, 0, 1, 2, 1, 2, 1, 2, 0, 1, 1]\n",
      "rr  0\n",
      "done  False\n",
      "free_columns:  [0, 1, 2, 3, 4, 5, 6]\n",
      "action  4\n",
      "next_state  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 2, 0, 2, 1, 1, 0, 0, 2, 0, 1, 2, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 1, 1]\n",
      "rr  0\n",
      "done  False\n",
      "free_columns:  [0, 1, 2, 3, 4, 5, 6]\n",
      "action  5\n",
      "next_state  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 2, 0, 0, 0, 2, 0, 2, 1, 1, 0, 2, 2, 0, 1, 2, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 1, 1]\n",
      "rr  0\n",
      "done  False\n",
      "free_columns:  [0, 1, 2, 3, 4, 5, 6]\n",
      "action  1\n",
      "next_state  [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 2, 0, 0, 0, 2, 0, 2, 1, 1, 2, 2, 2, 0, 1, 2, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 1, 1]\n",
      "rr  0\n",
      "done  False\n",
      "free_columns:  [0, 1, 2, 3, 4, 5, 6]\n",
      "action  4\n",
      "next_state  [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 2, 2, 0, 0, 1, 2, 0, 2, 1, 1, 2, 2, 2, 0, 1, 2, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 1, 1]\n",
      "rr  0\n",
      "done  False\n",
      "free_columns:  [0, 1, 2, 3, 4, 5, 6]\n",
      "action  1\n",
      "next_state  [0, 1, 0, 0, 0, 2, 0, 0, 1, 0, 0, 0, 1, 0, 2, 2, 0, 0, 1, 2, 0, 2, 1, 1, 2, 2, 2, 0, 1, 2, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 1, 1]\n",
      "rr  0\n",
      "done  False\n",
      "free_columns:  [0, 2, 3, 4, 6]\n",
      "action  0\n",
      "next_state  [0, 1, 0, 0, 0, 2, 0, 1, 1, 0, 0, 0, 1, 0, 2, 2, 0, 2, 1, 2, 0, 2, 1, 1, 2, 2, 2, 0, 1, 2, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 1, 1]\n",
      "rr  0\n",
      "done  False\n",
      "free_columns:  [0, 2, 3, 4, 6]\n",
      "action  0\n",
      "next_state  [1, 1, 0, 0, 0, 2, 0, 1, 1, 0, 0, 0, 1, 0, 2, 2, 0, 2, 1, 2, 0, 2, 1, 1, 2, 2, 2, 2, 1, 2, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 1, 1]\n",
      "rr  -1\n",
      "done  True\n",
      "Episode 11 | Total point average of the last 100 episodes: -0.27free_columns:  [0, 1, 2, 3, 4, 5, 6]\n",
      "action  6\n",
      "next_state  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 1]\n",
      "rr  0\n",
      "done  False\n",
      "free_columns:  [0, 1, 2, 3, 4, 5, 6]\n",
      "action  0\n",
      "next_state  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 0, 0, 2, 0, 1]\n",
      "rr  0\n",
      "done  False\n",
      "free_columns:  [0, 1, 2, 3, 4, 5, 6]\n",
      "action  3\n",
      "next_state  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 0, 1, 2, 2, 1]\n",
      "rr  0\n",
      "done  False\n",
      "free_columns:  [0, 1, 2, 3, 4, 5, 6]\n",
      "action  0\n",
      "next_state  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 2, 0, 1, 2, 0, 1, 2, 2, 1]\n",
      "rr  0\n",
      "done  False\n",
      "free_columns:  [0, 1, 2, 3, 4, 5, 6]\n",
      "action  0\n",
      "next_state  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 2, 0, 0, 0, 2, 0, 1, 2, 0, 1, 2, 2, 1]\n",
      "rr  0\n",
      "done  False\n",
      "free_columns:  [0, 1, 2, 3, 4, 5, 6]\n",
      "action  6\n",
      "next_state  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 2, 1, 2, 0, 0, 0, 2, 1, 1, 2, 0, 1, 2, 2, 1]\n",
      "rr  0\n",
      "done  False\n",
      "free_columns:  [0, 1, 2, 3, 4, 5, 6]\n",
      "action  5\n",
      "next_state  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 2, 1, 2, 0, 2, 0, 2, 1, 1, 2, 0, 1, 2, 2, 1]\n",
      "rr  0\n",
      "done  False\n",
      "free_columns:  [0, 1, 2, 3, 4, 5, 6]\n",
      "action  5\n",
      "next_state  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 1, 0, 0, 0, 0, 1, 2, 1, 2, 0, 2, 0, 2, 1, 1, 2, 0, 1, 2, 2, 1]\n",
      "rr  0\n",
      "done  False\n",
      "free_columns:  [0, 1, 2, 3, 4, 5, 6]\n",
      "action  5\n",
      "next_state  [0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 2, 1, 0, 0, 0, 0, 1, 2, 1, 2, 0, 2, 0, 2, 1, 1, 2, 0, 1, 2, 2, 1]\n",
      "rr  0\n",
      "done  False\n",
      "free_columns:  [0, 1, 2, 3, 4, 6]\n",
      "action  6\n",
      "next_state  [0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 2, 1, 0, 0, 2, 0, 1, 2, 1, 2, 0, 2, 0, 2, 1, 1, 2, 0, 1, 2, 2, 1]\n",
      "rr  0\n",
      "done  False\n",
      "free_columns:  [0, 1, 2, 3, 4, 6]\n",
      "action  0\n",
      "next_state  [0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 2, 1, 0, 0, 2, 0, 1, 2, 1, 2, 0, 2, 0, 2, 1, 1, 2, 0, 1, 2, 2, 1]\n",
      "rr  1\n",
      "done  True\n",
      "Episode 12 | Total point average of the last 100 episodes: -0.17free_columns:  [0, 1, 2, 3, 4, 5, 6]\n",
      "action  6\n",
      "next_state  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 1]\n",
      "rr  0\n",
      "done  False\n",
      "free_columns:  [0, 1, 2, 3, 4, 5, 6]\n",
      "action  6\n",
      "next_state  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 1, 2, 0, 0, 0, 0, 0, 1]\n",
      "rr  0\n",
      "done  False\n",
      "free_columns:  [0, 1, 2, 3, 4, 5, 6]\n",
      "action  2\n",
      "next_state  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 2, 0, 0, 0, 1, 2, 0, 1, 0, 0, 0, 1]\n",
      "rr  0\n",
      "done  False\n",
      "free_columns:  [0, 1, 2, 3, 4, 5, 6]\n",
      "action  6\n",
      "next_state  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 2, 2, 0, 2, 0, 0, 0, 1, 2, 0, 1, 0, 0, 0, 1]\n",
      "rr  0\n",
      "done  False\n",
      "free_columns:  [0, 1, 2, 3, 4, 5, 6]\n",
      "action  1\n",
      "next_state  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 0, 0, 0, 0, 0, 2, 2, 0, 2, 0, 0, 0, 1, 2, 1, 1, 0, 0, 0, 1]\n",
      "rr  0\n",
      "done  False\n",
      "free_columns:  [0, 1, 2, 3, 4, 5, 6]\n",
      "action  2\n",
      "next_state  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 0, 1, 0, 0, 0, 2, 2, 0, 2, 0, 0, 0, 1, 2, 1, 1, 0, 2, 0, 1]\n",
      "rr  0\n",
      "done  False\n",
      "free_columns:  [0, 1, 2, 3, 4, 5, 6]\n",
      "action  1\n",
      "next_state  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 0, 1, 0, 0, 0, 2, 2, 1, 2, 0, 2, 0, 1, 2, 1, 1, 0, 2, 0, 1]\n",
      "rr  0\n",
      "done  False\n",
      "free_columns:  [0, 1, 2, 3, 4, 5, 6]\n",
      "action  5\n",
      "next_state  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 0, 1, 0, 0, 0, 2, 2, 1, 2, 0, 2, 0, 1, 2, 1, 1, 2, 2, 1, 1]\n",
      "rr  0\n",
      "done  False\n",
      "free_columns:  [0, 1, 2, 3, 4, 5, 6]\n",
      "action  1\n",
      "next_state  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 1, 2, 1, 1, 0, 0, 0, 2, 2, 1, 2, 0, 2, 0, 1, 2, 1, 1, 2, 2, 1, 1]\n",
      "rr  0\n",
      "done  False\n",
      "free_columns:  [0, 1, 2, 3, 4, 5, 6]\n",
      "action  3\n",
      "next_state  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 1, 2, 1, 1, 0, 2, 0, 2, 2, 1, 2, 1, 2, 0, 1, 2, 1, 1, 2, 2, 1, 1]\n",
      "rr  0\n",
      "done  False\n",
      "free_columns:  [0, 1, 2, 3, 4, 5, 6]\n",
      "action  0\n",
      "next_state  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 1, 0, 0, 0, 0, 0, 1, 2, 1, 1, 2, 2, 0, 2, 2, 1, 2, 1, 2, 0, 1, 2, 1, 1, 2, 2, 1, 1]\n",
      "rr  0\n",
      "done  False\n",
      "free_columns:  [0, 1, 2, 3, 4, 5, 6]\n",
      "action  2\n",
      "next_state  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 1, 2, 1, 0, 0, 0, 1, 2, 1, 1, 2, 2, 0, 2, 2, 1, 2, 1, 2, 0, 1, 2, 1, 1, 2, 2, 1, 1]\n",
      "rr  0\n",
      "done  False\n",
      "free_columns:  [0, 1, 2, 3, 4, 5, 6]\n",
      "action  4\n",
      "next_state  [0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 2, 1, 2, 1, 0, 1, 0, 1, 2, 1, 1, 2, 2, 0, 2, 2, 1, 2, 1, 2, 0, 1, 2, 1, 1, 2, 2, 1, 1]\n",
      "rr  0\n",
      "done  False\n",
      "free_columns:  [0, 1, 2, 3, 4, 5, 6]\n",
      "action  0\n",
      "next_state  [0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 0, 0, 0, 2, 1, 2, 1, 0, 1, 0, 1, 2, 1, 1, 2, 2, 0, 2, 2, 1, 2, 1, 2, 0, 1, 2, 1, 1, 2, 2, 1, 1]\n",
      "rr  0\n",
      "done  False\n",
      "free_columns:  [0, 1, 2, 3, 4, 5, 6]\n",
      "action  0\n",
      "next_state  [1, 0, 2, 0, 0, 0, 0, 1, 2, 2, 0, 0, 0, 2, 1, 2, 1, 0, 1, 0, 1, 2, 1, 1, 2, 2, 0, 2, 2, 1, 2, 1, 2, 0, 1, 2, 1, 1, 2, 2, 1, 1]\n",
      "rr  0\n",
      "done  False\n",
      "free_columns:  [1, 3, 4, 5, 6]\n",
      "action  5\n",
      "next_state  [1, 0, 2, 0, 0, 0, 0, 1, 2, 2, 0, 0, 0, 2, 1, 2, 1, 2, 1, 0, 1, 2, 1, 1, 2, 2, 0, 2, 2, 1, 2, 1, 2, 1, 1, 2, 1, 1, 2, 2, 1, 1]\n",
      "rr  0\n",
      "done  False\n",
      "free_columns:  [1, 3, 4, 5, 6]\n",
      "action  5\n",
      "next_state  [1, 0, 2, 0, 0, 0, 2, 1, 2, 2, 0, 0, 0, 2, 1, 2, 1, 2, 1, 0, 1, 2, 1, 1, 2, 2, 1, 2, 2, 1, 2, 1, 2, 1, 1, 2, 1, 1, 2, 2, 1, 1]\n",
      "rr  0\n",
      "done  False\n",
      "free_columns:  [1, 3, 4, 5]\n",
      "action  1\n",
      "next_state  [1, 1, 2, 0, 0, 0, 2, 1, 2, 2, 2, 0, 0, 2, 1, 2, 1, 2, 1, 0, 1, 2, 1, 1, 2, 2, 1, 2, 2, 1, 2, 1, 2, 1, 1, 2, 1, 1, 2, 2, 1, 1]\n",
      "rr  0\n",
      "done  False\n",
      "free_columns:  [3, 4, 5]\n",
      "action  3\n",
      "next_state  [1, 1, 2, 1, 0, 0, 2, 1, 2, 2, 2, 2, 0, 2, 1, 2, 1, 2, 1, 0, 1, 2, 1, 1, 2, 2, 1, 2, 2, 1, 2, 1, 2, 1, 1, 2, 1, 1, 2, 2, 1, 1]\n",
      "rr  -1\n",
      "done  True\n",
      "Episode 13 | Total point average of the last 100 episodes: -0.23free_columns:  [0, 1, 2, 3, 4, 5, 6]\n",
      "action  3\n",
      "next_state  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 2]\n",
      "rr  0\n",
      "done  False\n",
      "free_columns:  [0, 1, 2, 3, 4, 5, 6]\n",
      "action  4\n",
      "next_state  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 1, 1, 0, 2]\n",
      "rr  0\n",
      "done  False\n",
      "free_columns:  [0, 1, 2, 3, 4, 5, 6]\n",
      "action  0\n",
      "next_state  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 2, 0, 0, 1, 1, 2, 2]\n",
      "rr  0\n",
      "done  False\n",
      "free_columns:  [0, 1, 2, 3, 4, 5, 6]\n",
      "action  1\n",
      "next_state  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 0, 0, 0, 0, 0, 2, 1, 0, 1, 1, 2, 2]\n",
      "rr  0\n",
      "done  False\n",
      "free_columns:  [0, 1, 2, 3, 4, 5, 6]\n",
      "action  0\n",
      "next_state  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 2, 0, 2, 0, 0, 0, 2, 1, 0, 1, 1, 2, 2]\n",
      "rr  0\n",
      "done  False\n",
      "free_columns:  [0, 1, 2, 3, 4, 5, 6]\n",
      "action  2\n",
      "next_state  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 2, 0, 2, 0, 0, 0, 2, 1, 1, 1, 1, 2, 2]\n",
      "rr  1\n",
      "done  True\n",
      "Episode 14 | Total point average of the last 100 episodes: -0.14free_columns:  [0, 1, 2, 3, 4, 5, 6]\n",
      "action  3\n",
      "next_state  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 1, 0, 0, 0]\n",
      "rr  0\n",
      "done  False\n",
      "free_columns:  [0, 1, 2, 3, 4, 5, 6]\n",
      "action  5\n",
      "next_state  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 2, 0, 0, 1, 0, 1, 0]\n",
      "rr  0\n",
      "done  False\n",
      "free_columns:  [0, 1, 2, 3, 4, 5, 6]\n",
      "action  4\n",
      "next_state  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 2, 0, 0, 1, 1, 1, 2]\n",
      "rr  0\n",
      "done  False\n",
      "free_columns:  [0, 1, 2, 3, 4, 5, 6]\n",
      "action  1\n",
      "next_state  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 2, 0, 2, 1, 0, 1, 1, 1, 2]\n",
      "rr  0\n",
      "done  False\n",
      "free_columns:  [0, 1, 2, 3, 4, 5, 6]\n",
      "action  5\n",
      "next_state  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 2, 2, 2, 0, 2, 1, 0, 1, 1, 1, 2]\n",
      "rr  0\n",
      "done  False\n",
      "free_columns:  [0, 1, 2, 3, 4, 5, 6]\n",
      "action  1\n",
      "next_state  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 1, 0, 0, 1, 0, 2, 2, 2, 0, 2, 1, 0, 1, 1, 1, 2]\n",
      "rr  0\n",
      "done  False\n",
      "free_columns:  [0, 1, 2, 3, 4, 5, 6]\n",
      "action  0\n",
      "next_state  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 1, 0, 1, 1, 0, 2, 2, 2, 2, 2, 1, 0, 1, 1, 1, 2]\n",
      "rr  -1\n",
      "done  True\n",
      "Episode 15 | Total point average of the last 100 episodes: -0.20free_columns:  [0, 1, 2, 3, 4, 5, 6]\n",
      "action  1\n",
      "next_state  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 1, 0, 0, 0, 0, 0]\n",
      "rr  0\n",
      "done  False\n",
      "free_columns:  [0, 1, 2, 3, 4, 5, 6]\n",
      "action  5\n",
      "next_state  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 1, 0, 2, 0, 1, 0]\n",
      "rr  0\n",
      "done  False\n",
      "free_columns:  [0, 1, 2, 3, 4, 5, 6]\n",
      "action  2\n",
      "next_state  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 1, 1, 2, 0, 1, 2]\n",
      "rr  0\n",
      "done  False\n",
      "free_columns:  [0, 1, 2, 3, 4, 5, 6]\n",
      "action  6\n",
      "next_state  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 1, 2, 1, 1, 2, 0, 1, 2]\n",
      "rr  0\n",
      "done  False\n",
      "free_columns:  [0, 1, 2, 3, 4, 5, 6]\n",
      "action  3\n",
      "next_state  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 0, 0, 1, 0, 0, 1, 2, 1, 1, 2, 0, 1, 2]\n",
      "rr  0\n",
      "done  False\n",
      "free_columns:  [0, 1, 2, 3, 4, 5, 6]\n",
      "action  3\n",
      "next_state  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 2, 2, 0, 2, 1, 0, 0, 1, 2, 1, 1, 2, 0, 1, 2]\n",
      "rr  0\n",
      "done  False\n",
      "free_columns:  [0, 1, 2, 3, 4, 5, 6]\n",
      "action  0\n",
      "next_state  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 2, 2, 0, 2, 1, 0, 0, 1, 2, 1, 1, 2, 0, 1, 2]\n",
      "rr  0\n",
      "done  False\n",
      "free_columns:  [0, 1, 2, 3, 4, 5, 6]\n",
      "action  1\n",
      "next_state  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 2, 0, 0, 0, 1, 0, 0, 1, 0, 0, 2, 2, 1, 2, 1, 0, 0, 1, 2, 1, 1, 2, 0, 1, 2]\n",
      "rr  0\n",
      "done  False\n",
      "free_columns:  [0, 1, 2, 3, 4, 5, 6]\n",
      "action  0\n",
      "next_state  [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 2, 0, 0, 2, 0, 0, 0, 1, 0, 0, 1, 0, 0, 2, 2, 1, 2, 1, 0, 2, 1, 2, 1, 1, 2, 0, 1, 2]\n",
      "rr  0\n",
      "done  False\n",
      "free_columns:  [0, 1, 2, 3, 4, 5, 6]\n",
      "action  4\n",
      "next_state  [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 2, 0, 0, 2, 0, 0, 0, 1, 0, 0, 1, 0, 0, 2, 2, 1, 2, 1, 2, 2, 1, 2, 1, 1, 2, 1, 1, 2]\n",
      "rr  0\n",
      "done  False\n",
      "free_columns:  [0, 1, 2, 3, 4, 5, 6]\n",
      "action  3\n",
      "next_state  [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 2, 0, 0, 2, 0, 0, 0, 1, 0, 2, 1, 0, 0, 2, 2, 1, 2, 1, 2, 2, 1, 2, 1, 1, 2, 1, 1, 2]\n",
      "rr  0\n",
      "done  False\n",
      "free_columns:  [0, 1, 2, 3, 4, 5, 6]\n",
      "action  4\n",
      "next_state  [2, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 2, 0, 0, 2, 0, 0, 0, 1, 0, 2, 1, 1, 0, 2, 2, 1, 2, 1, 2, 2, 1, 2, 1, 1, 2, 1, 1, 2]\n",
      "rr  0\n",
      "done  False\n",
      "free_columns:  [1, 2, 3, 4, 5, 6]\n",
      "action  1\n",
      "next_state  [2, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 2, 0, 0, 2, 2, 0, 0, 1, 1, 2, 1, 1, 0, 2, 2, 1, 2, 1, 2, 2, 1, 2, 1, 1, 2, 1, 1, 2]\n",
      "rr  0\n",
      "done  False\n",
      "free_columns:  [1, 2, 3, 4, 5, 6]\n",
      "action  4\n",
      "next_state  [2, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 2, 0, 2, 2, 2, 0, 0, 1, 1, 2, 1, 1, 0, 2, 2, 1, 2, 1, 2, 2, 1, 2, 1, 1, 2, 1, 1, 2]\n",
      "rr  0\n",
      "done  False\n",
      "free_columns:  [1, 2, 3, 4, 5, 6]\n",
      "action  4\n",
      "next_state  [2, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 2, 2, 2, 2, 2, 0, 0, 1, 1, 2, 1, 1, 0, 2, 2, 1, 2, 1, 2, 2, 1, 2, 1, 1, 2, 1, 1, 2]\n",
      "rr  -1\n",
      "done  True\n",
      "Episode 16 | Total point average of the last 100 episodes: -0.25free_columns:  [0, 1, 2, 3, 4, 5, 6]\n",
      "action  0\n",
      "next_state  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 0, 0, 0, 0, 0]\n",
      "rr  0\n",
      "done  False\n",
      "free_columns:  [0, 1, 2, 3, 4, 5, 6]\n",
      "action  5\n",
      "next_state  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 1, 2, 0, 0, 0, 1, 0]\n",
      "rr  0\n",
      "done  False\n",
      "free_columns:  [0, 1, 2, 3, 4, 5, 6]\n",
      "action  6\n",
      "next_state  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 1, 2, 0, 0, 0, 1, 1]\n",
      "rr  0\n",
      "done  False\n",
      "free_columns:  [0, 1, 2, 3, 4, 5, 6]\n",
      "action  6\n",
      "next_state  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 2, 2, 0, 0, 0, 0, 1, 1, 2, 0, 0, 0, 1, 1]\n",
      "rr  0\n",
      "done  False\n",
      "free_columns:  [0, 1, 2, 3, 4, 5, 6]\n",
      "action  6\n",
      "next_state  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 1, 2, 2, 0, 0, 0, 2, 1, 1, 2, 0, 0, 0, 1, 1]\n",
      "rr  0\n",
      "done  False\n",
      "free_columns:  [0, 1, 2, 3, 4, 5, 6]\n",
      "action  4\n",
      "next_state  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 1, 2, 2, 0, 0, 0, 2, 1, 1, 2, 0, 0, 1, 1, 1]\n",
      "rr  0\n",
      "done  False\n",
      "free_columns:  [0, 1, 2, 3, 4, 5, 6]\n",
      "action  4\n",
      "next_state  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 2, 1, 2, 2, 0, 0, 1, 2, 1, 1, 2, 0, 0, 1, 1, 1]\n",
      "rr  0\n",
      "done  False\n",
      "free_columns:  [0, 1, 2, 3, 4, 5, 6]\n",
      "action  0\n",
      "next_state  [2, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 2, 1, 2, 2, 0, 0, 1, 2, 1, 1, 2, 0, 0, 1, 1, 1]\n",
      "rr  0\n",
      "done  False\n",
      "free_columns:  [1, 2, 3, 4, 5, 6]\n",
      "action  1\n",
      "next_state  [2, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 2, 1, 0, 0, 0, 2, 1, 2, 2, 0, 0, 1, 2, 1, 1, 2, 0, 2, 1, 1, 1]\n",
      "rr  0\n",
      "done  False\n",
      "free_columns:  [1, 2, 3, 4, 5, 6]\n",
      "action  4\n",
      "next_state  [2, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 2, 0, 2, 1, 0, 0, 1, 2, 1, 2, 2, 0, 0, 1, 2, 1, 1, 2, 0, 2, 1, 1, 1]\n",
      "rr  0\n",
      "done  False\n",
      "free_columns:  [1, 2, 3, 4, 5, 6]\n",
      "action  5\n",
      "next_state  [2, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 2, 0, 0, 0, 0, 2, 0, 2, 1, 0, 0, 1, 2, 1, 2, 2, 0, 2, 1, 2, 1, 1, 2, 0, 2, 1, 1, 1]\n",
      "rr  0\n",
      "done  False\n",
      "free_columns:  [1, 2, 3, 4, 5, 6]\n",
      "action  4\n",
      "next_state  [2, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 2, 0, 0, 0, 1, 2, 0, 2, 1, 0, 0, 1, 2, 1, 2, 2, 0, 2, 1, 2, 1, 1, 2, 0, 2, 1, 1, 1]\n",
      "rr  1\n",
      "done  True\n",
      "Episode 17 | Total point average of the last 100 episodes: -0.18free_columns:  [0, 1, 2, 3, 4, 5, 6]\n",
      "action  4\n",
      "next_state  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 1, 0, 0]\n",
      "rr  0\n",
      "done  False\n",
      "free_columns:  [0, 1, 2, 3, 4, 5, 6]\n",
      "action  3\n",
      "next_state  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 2, 2, 1, 0, 0]\n",
      "rr  0\n",
      "done  False\n",
      "free_columns:  [0, 1, 2, 3, 4, 5, 6]\n",
      "action  2\n",
      "next_state  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 2, 2, 1, 2, 0]\n",
      "rr  0\n",
      "done  False\n",
      "free_columns:  [0, 1, 2, 3, 4, 5, 6]\n",
      "action  6\n",
      "next_state  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 2, 0, 0, 0, 2, 2, 1, 2, 1]\n",
      "rr  0\n",
      "done  False\n",
      "free_columns:  [0, 1, 2, 3, 4, 5, 6]\n",
      "action  0\n",
      "next_state  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 1, 1, 0, 2, 0, 1, 0, 2, 2, 1, 2, 1]\n",
      "rr  0\n",
      "done  False\n",
      "free_columns:  [0, 1, 2, 3, 4, 5, 6]\n",
      "action  6\n",
      "next_state  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 2, 0, 0, 1, 1, 0, 2, 1, 1, 0, 2, 2, 1, 2, 1]\n",
      "rr  0\n",
      "done  False\n",
      "free_columns:  [0, 1, 2, 3, 4, 5, 6]\n",
      "action  3\n",
      "next_state  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 2, 1, 0, 0, 2, 0, 0, 1, 1, 0, 2, 1, 1, 0, 2, 2, 1, 2, 1]\n",
      "rr  0\n",
      "done  False\n",
      "free_columns:  [0, 1, 2, 3, 4, 5, 6]\n",
      "action  6\n",
      "next_state  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 2, 0, 0, 0, 2, 0, 0, 2, 1, 0, 0, 2, 0, 0, 1, 1, 0, 2, 1, 1, 0, 2, 2, 1, 2, 1]\n",
      "rr  0\n",
      "done  False\n",
      "free_columns:  [0, 1, 2, 3, 4, 5, 6]\n",
      "action  2\n",
      "next_state  [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 2, 0, 0, 0, 2, 0, 0, 2, 1, 0, 0, 2, 2, 0, 1, 1, 0, 2, 1, 1, 0, 2, 2, 1, 2, 1]\n",
      "rr  0\n",
      "done  False\n",
      "free_columns:  [0, 1, 2, 3, 4, 5, 6]\n",
      "action  4\n",
      "next_state  [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 2, 2, 0, 0, 2, 0, 0, 2, 1, 0, 0, 2, 2, 0, 1, 1, 1, 2, 1, 1, 0, 2, 2, 1, 2, 1]\n",
      "rr  0\n",
      "done  False\n",
      "free_columns:  [0, 1, 2, 3, 4, 5, 6]\n",
      "action  0\n",
      "next_state  [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 2, 2, 0, 0, 2, 1, 0, 2, 1, 0, 0, 2, 2, 0, 1, 1, 1, 2, 1, 1, 2, 2, 2, 1, 2, 1]\n",
      "rr  0\n",
      "done  False\n",
      "free_columns:  [0, 1, 2, 3, 4, 5, 6]\n",
      "action  1\n",
      "next_state  [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 2, 2, 0, 0, 2, 1, 0, 2, 1, 0, 0, 2, 2, 1, 1, 1, 1, 2, 1, 1, 2, 2, 2, 1, 2, 1]\n",
      "rr  1\n",
      "done  True\n",
      "Episode 18 | Total point average of the last 100 episodes: -0.11free_columns:  [0, 1, 2, 3, 4, 5, 6]\n",
      "action  6\n",
      "next_state  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 1]\n",
      "rr  0\n",
      "done  False\n",
      "free_columns:  [0, 1, 2, 3, 4, 5, 6]\n",
      "action  2\n",
      "next_state  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 1]\n",
      "rr  0\n",
      "done  False\n",
      "free_columns:  [0, 1, 2, 3, 4, 5, 6]\n",
      "action  4\n",
      "next_state  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 1, 0, 2, 0, 0, 0, 0, 2, 0, 1, 0, 1]\n",
      "rr  0\n",
      "done  False\n",
      "free_columns:  [0, 1, 2, 3, 4, 5, 6]\n",
      "action  6\n",
      "next_state  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 1, 0, 2, 0, 1, 2, 0, 2, 0, 1, 0, 1]\n",
      "rr  0\n",
      "done  False\n",
      "free_columns:  [0, 1, 2, 3, 4, 5, 6]\n",
      "action  3\n",
      "next_state  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 1, 2, 2, 0, 1, 2, 0, 2, 1, 1, 0, 1]\n",
      "rr  0\n",
      "done  False\n",
      "free_columns:  [0, 1, 2, 3, 4, 5, 6]\n",
      "action  1\n",
      "next_state  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 2, 0, 1, 2, 2, 0, 1, 2, 1, 2, 1, 1, 0, 1]\n",
      "rr  0\n",
      "done  False\n",
      "free_columns:  [0, 1, 2, 3, 4, 5, 6]\n",
      "action  0\n",
      "next_state  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 1, 0, 2, 0, 0, 0, 0, 2, 0, 1, 2, 2, 0, 1, 2, 1, 2, 1, 1, 0, 1]\n",
      "rr  0\n",
      "done  False\n",
      "free_columns:  [0, 1, 2, 3, 4, 5, 6]\n",
      "action  6\n",
      "next_state  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 1, 0, 2, 0, 0, 0, 1, 2, 2, 1, 2, 2, 0, 1, 2, 1, 2, 1, 1, 0, 1]\n",
      "rr  0\n",
      "done  False\n",
      "free_columns:  [0, 1, 2, 3, 4, 5, 6]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [53], line 38\u001b[0m\n\u001b[1;32m     32\u001b[0m action \u001b[39m=\u001b[39m get_action(state, env\u001b[39m.\u001b[39mconfiguration, q_values, epsilon)\n\u001b[1;32m     34\u001b[0m \u001b[39m# Take action A and receive reward R and the next state S'\u001b[39;00m\n\u001b[1;32m     35\u001b[0m \u001b[39m# todo: state != board\u001b[39;00m\n\u001b[1;32m     36\u001b[0m \u001b[39m# todo: myagent function\u001b[39;00m\n\u001b[1;32m     37\u001b[0m \u001b[39m# todo: observe board before choosing an action\u001b[39;00m\n\u001b[0;32m---> 38\u001b[0m next_obs, reward, done, _ \u001b[39m=\u001b[39m trainer\u001b[39m.\u001b[39;49mstep(action)\n\u001b[1;32m     39\u001b[0m next_state \u001b[39m=\u001b[39m next_obs\u001b[39m.\u001b[39mboard\n\u001b[1;32m     40\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39maction \u001b[39m\u001b[39m'\u001b[39m, action)\n",
      "File \u001b[0;32m~/.virtualenvs/checkers_ai_env/lib/python3.10/site-packages/kaggle_environments/core.py:423\u001b[0m, in \u001b[0;36mEnvironment.train.<locals>.step\u001b[0;34m(action)\u001b[0m\n\u001b[1;32m    421\u001b[0m actions, logs \u001b[39m=\u001b[39m runner\u001b[39m.\u001b[39mact(action)\n\u001b[1;32m    422\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstep(actions, logs)\n\u001b[0;32m--> 423\u001b[0m advance()\n\u001b[1;32m    424\u001b[0m agent \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__get_shared_state(position)\n\u001b[1;32m    425\u001b[0m reward \u001b[39m=\u001b[39m agent\u001b[39m.\u001b[39mreward\n",
      "File \u001b[0;32m~/.virtualenvs/checkers_ai_env/lib/python3.10/site-packages/kaggle_environments/core.py:411\u001b[0m, in \u001b[0;36mEnvironment.train.<locals>.advance\u001b[0;34m()\u001b[0m\n\u001b[1;32m    409\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdone \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate[position]\u001b[39m.\u001b[39mstatus \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mINACTIVE\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    410\u001b[0m     actions, logs \u001b[39m=\u001b[39m runner\u001b[39m.\u001b[39mact()\n\u001b[0;32m--> 411\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstep(actions, logs)\n",
      "File \u001b[0;32m~/.virtualenvs/checkers_ai_env/lib/python3.10/site-packages/kaggle_environments/core.py:224\u001b[0m, in \u001b[0;36mEnvironment.step\u001b[0;34m(self, actions, logs)\u001b[0m\n\u001b[1;32m    222\u001b[0m     action_state[index][\u001b[39m\"\u001b[39m\u001b[39mstatus\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mERROR\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    223\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 224\u001b[0m     err, data \u001b[39m=\u001b[39m process_schema(\n\u001b[1;32m    225\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m__state_schema\u001b[39m.\u001b[39;49mproperties\u001b[39m.\u001b[39;49maction, action)\n\u001b[1;32m    226\u001b[0m     \u001b[39mif\u001b[39;00m err:\n\u001b[1;32m    227\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdebug_print(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mInvalid Action: \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mstr\u001b[39m(err)\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.virtualenvs/checkers_ai_env/lib/python3.10/site-packages/kaggle_environments/utils.py:170\u001b[0m, in \u001b[0;36mprocess_schema\u001b[0;34m(schema, data, use_default)\u001b[0m\n\u001b[1;32m    168\u001b[0m     data \u001b[39m=\u001b[39m default_schema(schema, deepcopy(data))\n\u001b[1;32m    169\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 170\u001b[0m     jsonschema\u001b[39m.\u001b[39;49mvalidate(data, schema)\n\u001b[1;32m    171\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[1;32m    172\u001b[0m     error \u001b[39m=\u001b[39m \u001b[39mstr\u001b[39m(err)\n",
      "File \u001b[0;32m~/.virtualenvs/checkers_ai_env/lib/python3.10/site-packages/jsonschema/validators.py:1112\u001b[0m, in \u001b[0;36mvalidate\u001b[0;34m(instance, schema, cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1109\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mcls\u001b[39m \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   1110\u001b[0m     \u001b[39mcls\u001b[39m \u001b[39m=\u001b[39m validator_for(schema)\n\u001b[0;32m-> 1112\u001b[0m \u001b[39mcls\u001b[39;49m\u001b[39m.\u001b[39;49mcheck_schema(schema)\n\u001b[1;32m   1113\u001b[0m validator \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39m(schema, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m   1114\u001b[0m error \u001b[39m=\u001b[39m exceptions\u001b[39m.\u001b[39mbest_match(validator\u001b[39m.\u001b[39miter_errors(instance))\n",
      "File \u001b[0;32m~/.virtualenvs/checkers_ai_env/lib/python3.10/site-packages/jsonschema/validators.py:226\u001b[0m, in \u001b[0;36mcreate.<locals>.Validator.check_schema\u001b[0;34m(cls, schema, format_checker)\u001b[0m\n\u001b[1;32m    221\u001b[0m     format_checker \u001b[39m=\u001b[39m Validator\u001b[39m.\u001b[39mFORMAT_CHECKER\n\u001b[1;32m    222\u001b[0m validator \u001b[39m=\u001b[39m Validator(\n\u001b[1;32m    223\u001b[0m     schema\u001b[39m=\u001b[39m\u001b[39mcls\u001b[39m\u001b[39m.\u001b[39mMETA_SCHEMA,\n\u001b[1;32m    224\u001b[0m     format_checker\u001b[39m=\u001b[39mformat_checker,\n\u001b[1;32m    225\u001b[0m )\n\u001b[0;32m--> 226\u001b[0m \u001b[39mfor\u001b[39;00m error \u001b[39min\u001b[39;00m validator\u001b[39m.\u001b[39miter_errors(schema):\n\u001b[1;32m    227\u001b[0m     \u001b[39mraise\u001b[39;00m exceptions\u001b[39m.\u001b[39mSchemaError\u001b[39m.\u001b[39mcreate_from(error)\n",
      "File \u001b[0;32m~/.virtualenvs/checkers_ai_env/lib/python3.10/site-packages/jsonschema/validators.py:284\u001b[0m, in \u001b[0;36mcreate.<locals>.Validator.iter_errors\u001b[0;34m(self, instance, _schema)\u001b[0m\n\u001b[1;32m    281\u001b[0m     \u001b[39mcontinue\u001b[39;00m\n\u001b[1;32m    283\u001b[0m errors \u001b[39m=\u001b[39m validator(\u001b[39mself\u001b[39m, v, instance, _schema) \u001b[39mor\u001b[39;00m ()\n\u001b[0;32m--> 284\u001b[0m \u001b[39mfor\u001b[39;00m error \u001b[39min\u001b[39;00m errors:\n\u001b[1;32m    285\u001b[0m     \u001b[39m# set details if not already set by the called fn\u001b[39;00m\n\u001b[1;32m    286\u001b[0m     error\u001b[39m.\u001b[39m_set(\n\u001b[1;32m    287\u001b[0m         validator\u001b[39m=\u001b[39mk,\n\u001b[1;32m    288\u001b[0m         validator_value\u001b[39m=\u001b[39mv,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    291\u001b[0m         type_checker\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mTYPE_CHECKER,\n\u001b[1;32m    292\u001b[0m     )\n\u001b[1;32m    293\u001b[0m     \u001b[39mif\u001b[39;00m k \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m {\u001b[39m\"\u001b[39m\u001b[39mif\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m$ref\u001b[39m\u001b[39m\"\u001b[39m}:\n",
      "File \u001b[0;32m~/.virtualenvs/checkers_ai_env/lib/python3.10/site-packages/jsonschema/_validators.py:362\u001b[0m, in \u001b[0;36mallOf\u001b[0;34m(validator, allOf, instance, schema)\u001b[0m\n\u001b[1;32m    360\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mallOf\u001b[39m(validator, allOf, instance, schema):\n\u001b[1;32m    361\u001b[0m     \u001b[39mfor\u001b[39;00m index, subschema \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(allOf):\n\u001b[0;32m--> 362\u001b[0m         \u001b[39myield from\u001b[39;00m validator\u001b[39m.\u001b[39mdescend(instance, subschema, schema_path\u001b[39m=\u001b[39mindex)\n",
      "File \u001b[0;32m~/.virtualenvs/checkers_ai_env/lib/python3.10/site-packages/jsonschema/validators.py:301\u001b[0m, in \u001b[0;36mcreate.<locals>.Validator.descend\u001b[0;34m(self, instance, schema, path, schema_path)\u001b[0m\n\u001b[1;32m    300\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdescend\u001b[39m(\u001b[39mself\u001b[39m, instance, schema, path\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, schema_path\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m--> 301\u001b[0m     \u001b[39mfor\u001b[39;00m error \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mevolve(schema\u001b[39m=\u001b[39mschema)\u001b[39m.\u001b[39miter_errors(instance):\n\u001b[1;32m    302\u001b[0m         \u001b[39mif\u001b[39;00m path \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    303\u001b[0m             error\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mappendleft(path)\n",
      "File \u001b[0;32m~/.virtualenvs/checkers_ai_env/lib/python3.10/site-packages/jsonschema/validators.py:284\u001b[0m, in \u001b[0;36mcreate.<locals>.Validator.iter_errors\u001b[0;34m(self, instance, _schema)\u001b[0m\n\u001b[1;32m    281\u001b[0m     \u001b[39mcontinue\u001b[39;00m\n\u001b[1;32m    283\u001b[0m errors \u001b[39m=\u001b[39m validator(\u001b[39mself\u001b[39m, v, instance, _schema) \u001b[39mor\u001b[39;00m ()\n\u001b[0;32m--> 284\u001b[0m \u001b[39mfor\u001b[39;00m error \u001b[39min\u001b[39;00m errors:\n\u001b[1;32m    285\u001b[0m     \u001b[39m# set details if not already set by the called fn\u001b[39;00m\n\u001b[1;32m    286\u001b[0m     error\u001b[39m.\u001b[39m_set(\n\u001b[1;32m    287\u001b[0m         validator\u001b[39m=\u001b[39mk,\n\u001b[1;32m    288\u001b[0m         validator_value\u001b[39m=\u001b[39mv,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    291\u001b[0m         type_checker\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mTYPE_CHECKER,\n\u001b[1;32m    292\u001b[0m     )\n\u001b[1;32m    293\u001b[0m     \u001b[39mif\u001b[39;00m k \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m {\u001b[39m\"\u001b[39m\u001b[39mif\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m$ref\u001b[39m\u001b[39m\"\u001b[39m}:\n",
      "File \u001b[0;32m~/.virtualenvs/checkers_ai_env/lib/python3.10/site-packages/jsonschema/_validators.py:298\u001b[0m, in \u001b[0;36mref\u001b[0;34m(validator, ref, instance, schema)\u001b[0m\n\u001b[1;32m    295\u001b[0m validator\u001b[39m.\u001b[39mresolver\u001b[39m.\u001b[39mpush_scope(scope)\n\u001b[1;32m    297\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 298\u001b[0m     \u001b[39myield from\u001b[39;00m validator\u001b[39m.\u001b[39mdescend(instance, resolved)\n\u001b[1;32m    299\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    300\u001b[0m     validator\u001b[39m.\u001b[39mresolver\u001b[39m.\u001b[39mpop_scope()\n",
      "File \u001b[0;32m~/.virtualenvs/checkers_ai_env/lib/python3.10/site-packages/jsonschema/validators.py:301\u001b[0m, in \u001b[0;36mcreate.<locals>.Validator.descend\u001b[0;34m(self, instance, schema, path, schema_path)\u001b[0m\n\u001b[1;32m    300\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdescend\u001b[39m(\u001b[39mself\u001b[39m, instance, schema, path\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, schema_path\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m--> 301\u001b[0m     \u001b[39mfor\u001b[39;00m error \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mevolve(schema\u001b[39m=\u001b[39mschema)\u001b[39m.\u001b[39miter_errors(instance):\n\u001b[1;32m    302\u001b[0m         \u001b[39mif\u001b[39;00m path \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    303\u001b[0m             error\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mappendleft(path)\n",
      "File \u001b[0;32m~/.virtualenvs/checkers_ai_env/lib/python3.10/site-packages/jsonschema/validators.py:276\u001b[0m, in \u001b[0;36mcreate.<locals>.Validator.iter_errors\u001b[0;34m(self, instance, _schema)\u001b[0m\n\u001b[1;32m    274\u001b[0m scope \u001b[39m=\u001b[39m id_of(_schema)\n\u001b[1;32m    275\u001b[0m \u001b[39mif\u001b[39;00m scope:\n\u001b[0;32m--> 276\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mresolver\u001b[39m.\u001b[39;49mpush_scope(scope)\n\u001b[1;32m    277\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    278\u001b[0m     \u001b[39mfor\u001b[39;00m k, v \u001b[39min\u001b[39;00m applicable_validators(_schema):\n",
      "File \u001b[0;32m~/.virtualenvs/checkers_ai_env/lib/python3.10/site-packages/jsonschema/validators.py:777\u001b[0m, in \u001b[0;36mRefResolver.push_scope\u001b[0;34m(self, scope)\u001b[0m\n\u001b[1;32m    769\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpush_scope\u001b[39m(\u001b[39mself\u001b[39m, scope):\n\u001b[1;32m    770\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    771\u001b[0m \u001b[39m    Enter a given sub-scope.\u001b[39;00m\n\u001b[1;32m    772\u001b[0m \n\u001b[1;32m    773\u001b[0m \u001b[39m    Treats further dereferences as being performed underneath the\u001b[39;00m\n\u001b[1;32m    774\u001b[0m \u001b[39m    given scope.\u001b[39;00m\n\u001b[1;32m    775\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m    776\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_scopes_stack\u001b[39m.\u001b[39mappend(\n\u001b[0;32m--> 777\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_urljoin_cache(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mresolution_scope, scope),\n\u001b[1;32m    778\u001b[0m     )\n",
      "File \u001b[0;32m/usr/lib64/python3.10/urllib/parse.py:534\u001b[0m, in \u001b[0;36murljoin\u001b[0;34m(base, url, allow_fragments)\u001b[0m\n\u001b[1;32m    530\u001b[0m     \u001b[39mreturn\u001b[39;00m base\n\u001b[1;32m    532\u001b[0m base, url, _coerce_result \u001b[39m=\u001b[39m _coerce_args(base, url)\n\u001b[1;32m    533\u001b[0m bscheme, bnetloc, bpath, bparams, bquery, bfragment \u001b[39m=\u001b[39m \\\n\u001b[0;32m--> 534\u001b[0m         urlparse(base, \u001b[39m'\u001b[39;49m\u001b[39m'\u001b[39;49m, allow_fragments)\n\u001b[1;32m    535\u001b[0m scheme, netloc, path, params, query, fragment \u001b[39m=\u001b[39m \\\n\u001b[1;32m    536\u001b[0m         urlparse(url, bscheme, allow_fragments)\n\u001b[1;32m    538\u001b[0m \u001b[39mif\u001b[39;00m scheme \u001b[39m!=\u001b[39m bscheme \u001b[39mor\u001b[39;00m scheme \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m uses_relative:\n",
      "File \u001b[0;32m/usr/lib64/python3.10/urllib/parse.py:393\u001b[0m, in \u001b[0;36murlparse\u001b[0;34m(url, scheme, allow_fragments)\u001b[0m\n\u001b[1;32m    373\u001b[0m \u001b[39m\"\"\"Parse a URL into 6 components:\u001b[39;00m\n\u001b[1;32m    374\u001b[0m \u001b[39m<scheme>://<netloc>/<path>;<params>?<query>#<fragment>\u001b[39;00m\n\u001b[1;32m    375\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    390\u001b[0m \u001b[39mNote that % escapes are not expanded.\u001b[39;00m\n\u001b[1;32m    391\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    392\u001b[0m url, scheme, _coerce_result \u001b[39m=\u001b[39m _coerce_args(url, scheme)\n\u001b[0;32m--> 393\u001b[0m splitresult \u001b[39m=\u001b[39m urlsplit(url, scheme, allow_fragments)\n\u001b[1;32m    394\u001b[0m scheme, netloc, url, query, fragment \u001b[39m=\u001b[39m splitresult\n\u001b[1;32m    395\u001b[0m \u001b[39mif\u001b[39;00m scheme \u001b[39min\u001b[39;00m uses_params \u001b[39mand\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39m;\u001b[39m\u001b[39m'\u001b[39m \u001b[39min\u001b[39;00m url:\n",
      "File \u001b[0;32m/usr/lib64/python3.10/urllib/parse.py:466\u001b[0m, in \u001b[0;36murlsplit\u001b[0;34m(url, scheme, allow_fragments)\u001b[0m\n\u001b[1;32m    464\u001b[0m allow_fragments \u001b[39m=\u001b[39m \u001b[39mbool\u001b[39m(allow_fragments)\n\u001b[1;32m    465\u001b[0m key \u001b[39m=\u001b[39m url, scheme, allow_fragments, \u001b[39mtype\u001b[39m(url), \u001b[39mtype\u001b[39m(scheme)\n\u001b[0;32m--> 466\u001b[0m cached \u001b[39m=\u001b[39m _parse_cache\u001b[39m.\u001b[39;49mget(key, \u001b[39mNone\u001b[39;49;00m)\n\u001b[1;32m    467\u001b[0m \u001b[39mif\u001b[39;00m cached:\n\u001b[1;32m    468\u001b[0m     \u001b[39mreturn\u001b[39;00m _coerce_result(cached)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "num_episodes = 2000\n",
    "max_num_timesteps = 1000\n",
    "\n",
    "total_point_history = []\n",
    "\n",
    "num_p_av = 100    # number of total points to use for averaging\n",
    "epsilon = 1.0     # initial Îµ value for Îµ-greedy policy\n",
    "\n",
    "# Create a memory buffer D with capacity N\n",
    "memory_buffer = deque(maxlen=MEMORY_SIZE)\n",
    "\n",
    "# Set the target network weights equal to the Q-Network weights\n",
    "target_q_network.set_weights(q_network.get_weights())\n",
    "\n",
    "for i in range(num_episodes):\n",
    "    \n",
    "    # Reset the environment to the initial state and get the initial state\n",
    "    trainer = env.train([None, \"random\"])\n",
    "    observation = trainer.reset()\n",
    "\n",
    "    state = observation.board\n",
    "    total_points = 0\n",
    "    \n",
    "    for t in range(max_num_timesteps):\n",
    "        \n",
    "        # From the current state S choose an action A using an Îµ-greedy policy\n",
    "        state_qn = np.expand_dims(state, axis=0)  # state needs to be the right shape for the q_network\n",
    "        q_values = q_network(state_qn)\n",
    "\n",
    "        action = get_action(state, env.configuration, q_values, epsilon)\n",
    "        \n",
    "        # Take action A and receive reward R and the next state S'\n",
    "        # todo: state != board\n",
    "        # todo: myagent function\n",
    "        # todo: observe board before choosing an action\n",
    "        next_obs, reward, done, _ = trainer.step(action)\n",
    "        next_state = next_obs.board\n",
    "        print('action ', action)\n",
    "        print('next_state ', next_state)\n",
    "        print('rr ', reward)\n",
    "        print('done ', done)\n",
    "        # env.render(mode=\"ipython\", width=100, height=90, header=False, controls=False)\n",
    "        \n",
    "        # Store experience tuple (S,A,R,S') in the memory buffer.\n",
    "        # We store the done variable as well for convenience.\n",
    "        memory_buffer.append(experience(state, action, reward, next_state, done))\n",
    "        \n",
    "        # Only update the network every NUM_STEPS_FOR_UPDATE time steps.\n",
    "        update = utils.check_update_conditions(t, NUM_STEPS_FOR_UPDATE, memory_buffer)\n",
    "        \n",
    "        if update:\n",
    "            # Sample random mini-batch of experience tuples (S,A,R,S') from D\n",
    "            experiences = utils.get_experiences(memory_buffer)\n",
    "            \n",
    "            # Set the y targets, perform a gradient descent step,\n",
    "            # and update the network weights.\n",
    "            agent_learn(experiences, GAMMA)\n",
    "        \n",
    "        state = next_state.copy()\n",
    "        total_points += reward\n",
    "        \n",
    "        if done:\n",
    "            break\n",
    "            \n",
    "    total_point_history.append(total_points)\n",
    "    av_latest_points = np.mean(total_point_history[-num_p_av:])\n",
    "    \n",
    "    # Update the Îµ value\n",
    "    epsilon = utils.get_new_eps(epsilon)\n",
    "\n",
    "    print(f\"\\rEpisode {i+1} | Total point average of the last {num_p_av} episodes: {av_latest_points:.2f}\", end=\"\")\n",
    "\n",
    "    if (i+1) % num_p_av == 0:\n",
    "        print(f\"\\rEpisode {i+1} | Total point average of the last {num_p_av} episodes: {av_latest_points:.2f}\")\n",
    "\n",
    "    # We will consider that the environment is solved if we get an\n",
    "    # average of 200 points in the last 100 episodes.\n",
    "    if av_latest_points >= 200.0:\n",
    "        print(f\"\\n\\nEnvironment solved in {i+1} episodes!\")\n",
    "        q_network.save('checkers_model.h5')\n",
    "        break\n",
    "        \n",
    "tot_time = time.time() - start\n",
    "\n",
    "print(f\"\\nTotal Runtime: {tot_time:.2f} s ({(tot_time/60):.2f} min)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 ('checkers_ai_env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "50627d21a49769c346a2b998667fdc29159d12dd29fbc34da6f93ed9f37d395d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
